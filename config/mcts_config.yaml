# MCTS Feature Discovery Configuration
# All parameters for MCTS, AutoGluon, SQLite, and system behavior

# Session Management
session:
  # Options: 'new', 'continue', 'resume_best'
  mode: 'new'                    # new: start fresh, continue: resume last session, resume_best: start from best node
  max_iterations: 20            # Total iteration limit
  max_runtime_hours: 12          # Maximum runtime in hours
  checkpoint_interval: 25        # Save progress every N iterations
  auto_save: true               # Auto-save session on interruption
  session_name: null            # Custom session name (null = auto-generate)

# MCTS Algorithm Parameters  
mcts:
  exploration_weight: 1.4       # UCB1 C parameter (higher = more exploration)
  max_tree_depth: 8            # Maximum depth of feature operation tree
  expansion_threshold: 3        # Minimum visits before expanding node
  min_visits_for_best: 10      # Min visits to consider node as "best"
  ucb1_confidence: 0.95        # Confidence level for UCB1
  
  # Node selection strategy
  selection_strategy: 'ucb1'    # Options: 'ucb1', 'uct', 'thompson_sampling'
  
  # Expansion control
  max_children_per_node: 5      # Max feature operations per expansion
  expansion_budget: 20          # Max new nodes per iteration
  
  # Memory management
  max_nodes_in_memory: 10000   # Max nodes to keep in memory
  prune_threshold: 0.1         # Remove nodes with reward < threshold

# AutoGluon Evaluation Settings
autogluon:
  # Base data paths (override in domain-specific configs)
  train_path: null
  test_path: null
  target_metric: null
  
  # Production AutoGluon Configuration
  included_model_types: ['XGB', 'GBM', 'CAT']  # XGBoost, LightGBM, CatBoost
  # Available: GBM, CAT, XGB, FASTAI, RF, XT, NN_TORCH, KNN
  enable_gpu: true                             # GPU acceleration
  train_size: 0.8                             # 80% of training data
  
  # Model training settings
  time_limit: 120                             # Seconds per evaluation
  presets: 'good_quality_faster_inference'    # good_quality, medium_quality_faster_train, best_quality
  num_bag_folds: 3                            # Cross-validation folds
  num_bag_sets: 1                             # Number of bagging sets
  holdout_frac: 0.2                           # Holdout fraction for validation
  verbosity: 1                                # 0=silent, 1=minimal, 2=verbose
  
  # Evaluation phases
  fast_eval:
    time_limit: 20                            # Fast exploration phase
    presets: 'good_quality_faster_inference'
  
  thorough_eval:
    time_limit: 60                            # Thorough exploitation phase
    presets: 'good_quality'
  
  thorough_eval_threshold: 0.7                # Switch to thorough eval at 70% of iterations
  
  # Final evaluation (best features only)
  final_eval:
    time_limit: 600                           # 10 minutes for final evaluation
    presets: 'best_quality'
    num_bag_folds: 5
    num_bag_sets: 2
    holdout_frac: 0.15
    verbosity: 2

# Feature Space Configuration
feature_space:
  # Feature generation limits
  max_features_per_node: 300    # Maximum features in any single node
  min_improvement_threshold: 0.0005  # Minimum MAP@3 improvement to consider
  feature_timeout: 300          # Max seconds to generate features
  
  # Feature categories to explore
  enabled_categories:
    - 'npk_interactions'
    - 'environmental_stress'  
    - 'agricultural_domain'
    - 'statistical_aggregations'
    - 'feature_transformations'
    - 'feature_selection'
    
  # Operation weights (higher = more likely to be selected)
  category_weights:
    npk_interactions: 2.0
    environmental_stress: 1.5
    agricultural_domain: 2.5     # Domain knowledge is valuable
    statistical_aggregations: 1.0
    feature_transformations: 0.8
    feature_selection: 0.5
    
  # Generation strategy
  lazy_loading: true            # Generate features on-demand
  cache_features: true          # Cache computed features
  max_cache_size_mb: 2048      # Max feature cache size in MB
  cache_cleanup_threshold: 0.8  # Cleanup when 80% full

# Database Configuration
database:
  path: '../data/feature_discovery.db'
  backup_path: '../data/backups/'
  backup_interval: 50           # Backup every N iterations
  max_history_size: 50000      # Max records in exploration_history
  max_backup_files: 10         # Keep last N backup files
  
  # Transaction settings
  batch_size: 10               # Batch DB operations
  sync_mode: 'NORMAL'          # NORMAL, FULL, OFF
  journal_mode: 'WAL'          # WAL, DELETE, TRUNCATE
  
  # Cleanup settings
  auto_cleanup: true
  cleanup_interval_hours: 24   # Cleanup old data every N hours
  retention_days: 30           # Keep data for N days

# Logging and Monitoring  
logging:
  level: 'INFO'                # DEBUG, INFO, WARNING, ERROR
  log_file: 'logs/mcts_discovery.log'
  max_log_size_mb: 100
  backup_count: 5
  
  # What to log
  log_feature_code: true       # Save Python code for features
  log_timing: true            # Track operation timing
  log_memory_usage: true      # Monitor memory consumption
  log_autogluon_details: false # Detailed AutoGluon logs (verbose)
  
  # Progress reporting
  progress_interval: 10        # Report progress every N iterations
  save_intermediate_results: true
  
# Performance and Resource Management
resources:
  # Memory management
  max_memory_gb: 16           # Maximum memory usage
  memory_check_interval: 5    # Check memory every N iterations
  force_gc_interval: 50       # Force garbage collection every N iterations
  
  # CPU/GPU settings
  use_gpu: true
  max_cpu_cores: -1           # -1 = use all available
  autogluon_num_cpus: null    # null = auto-detect
  
  # Disk management
  max_disk_usage_gb: 50       # Maximum disk usage for caches/logs
  temp_dir: '/tmp/mcts_features'
  cleanup_temp_on_exit: true

# LLM Integration (Optional)
llm:
  enabled: false              # Enable LLM-assisted feature generation
  provider: 'openai'          # 'openai', 'anthropic', 'local'
  model: 'gpt-4'
  api_key_env: 'OPENAI_API_KEY'
  
  # LLM usage frequency
  trigger_interval: 20        # Use LLM every N iterations
  trigger_on_plateau: true    # Use LLM when no improvement for N iterations
  plateau_threshold: 15       # No improvement for N iterations = plateau
  
  # Generation settings
  max_features_per_request: 5
  temperature: 0.7
  max_tokens: 1000
  
# Export and Reporting
export:
  # Output formats
  formats: ['python', 'json', 'html']
  
  # Python code export
  python_output: '../outputs/best_features_discovered.py'
  include_dependencies: true
  include_documentation: true
  code_style: 'pep8'
  
  # Report generation
  html_report: '../outputs/discovery_report.html'
  include_plots: true
  plot_format: 'png'
  
  # Analytics configuration
  include_analytics: true
  output_dir: '../outputs/reports'
  
  # Export triggers
  export_on_completion: true
  export_on_improvement: true  # Export when new best found
  export_interval: 100        # Export every N iterations

# Analytics Configuration
analytics:
  figure_size: [12, 8]
  dpi: 100
  format: 'png'
  generate_charts: true
  include_timing_analysis: true

# Testing Configuration (use --test-mode flag instead)
testing:
  use_mock_evaluator: false   # Use mock evaluator instead of AutoGluon
  mock_base_score: 0.30      # Base score for mock evaluator
  mock_score_variance: 0.05   # Random variance in mock scores

# Validation and Testing
validation:
  # Feature validation
  validate_generated_features: true
  max_validation_time: 60     # Seconds to validate features
  
  # Cross-validation for impact analysis
  cv_folds: 3
  cv_repeats: 1
  
  # Statistical significance testing
  significance_level: 0.05
  min_samples_for_test: 10

# Advanced Settings
advanced:
  # Experimental features
  enable_neural_mcts: false   # Use neural network for value estimation
  enable_parallel_evaluation: false  # Parallel AutoGluon evaluation
  enable_multi_objective: false      # Optimize multiple metrics
  
  # Debug settings
  debug_mode: false
  debug_save_all_features: false     # Save all generated features (expensive)
  debug_detailed_timing: false       # Detailed timing for each operation
  
  # Recovery settings
  auto_recovery: true         # Auto-recover from crashes
  max_recovery_attempts: 3
  recovery_checkpoint_interval: 10
